{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381dc150-3320-4f25-861f-8f196e604cd6",
   "metadata": {},
   "source": [
    "# Long-term Air Pollution Level Trend in New York City with the Clean Heat Program (CHP)\n",
    "## Final Project for EESC GR6901: Research Computing for the Earth Sciences\n",
    "Yuwei Zhao <br>\n",
    "December 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bce55d-fbb5-4ea7-85e1-f6062884c4d2",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "Air pollution such as fine particulate matter (PM 2.5), SO$_2$, NO$_x$, and CO can cause harm to human health and the environment worldwide. According to World Health Organization (WHO), in 2016, outdoor air pollution was estimated to cause 4.2 million premature death globally. One of the main outdoor air pollution sources are household energy for heating and cooking(World Health Organization, 2022). \n",
    "<br>\n",
    "\n",
    "<br>\n",
    "In 2012, New York City (NYC) established the Clean Heat Program (CHP) to ban #6 heating oil, and switch to cleaner heating fuel which has fewer sulfur and reactive nitrogen emissions during combustion. The #6 heating oil ban started in 2012 and was completed in 2016 (Berger, 2021). The purposes of the project are to look at the impacts of CHP on air quality in NYC and to analyze the chemical composition changes in combustion emissions after heating oil conversion.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "I looked at the trend of SO$_2$, NO$_x$, CO, and speciated PM 2.5 (sulfate, nitrate, ammonium) trend in NYC and NJ. In each area, I picked 2~4 monitor sites. \n",
    "<br>\n",
    "\n",
    "<br>\n",
    "References\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "Berger, S. (2021, December 8). Study shows success of New York City's Clean Heat Program. Search the website. Retrieved September 25, 2022, from https://www.publichealth.columbia.edu/public-health-now/news/study-shows-success-new-york-citys-clean-heat-program\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "World Health Organization. (2022). Air Pollution. World Health Organization. Retrieved December 5, 2022, from https://www.who.int/health-topics/air-pollution#tab=tab_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f62017e-adbb-403f-a64a-f825c0ad1d07",
   "metadata": {},
   "source": [
    "# Import all the package and function needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b036851e-bf39-4488-a200-6b76392b3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "pd.set_option('display.max_rows',10)\n",
    "pd.set_option('display.max_columns',500)\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "custom_xlim = ([datetime.date(2009, 12, 1), datetime.date(2022, 12, 31)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecb3cc-a0e3-451a-8a7f-731a10c03618",
   "metadata": {},
   "source": [
    "# Read in all years json data into dataframe at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a32466-ca94-4dab-b0a7-b59db75526c1",
   "metadata": {},
   "source": [
    "The original datasets are on Air Quality System (AQS) API database in daily data format. The URL to load data has a one-year time period limitation together with one pollutant species limitation. Since the data I need is the longtime period with multiple air pollutant species, I wrote a for loop to grab all years' .json data to dataframe at once. There are two ways to apply the for loop, one is to use the dictionary to loop through all 7 pollutants for 22 years in both NYC and NJ, and the other is to put in the area and pollutant you want, and it gets 12 years data for that specific pollutants only. Since the dataset is huge, when applying the first method to run the full for loop, the server breaks down. Therefore I applied the second one. But the code that applies the dictionary and full loop is in the appendix section at the end.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "The individual pollutant data was saved as .txt file for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89be9128-78c9-46bd-970f-e2bfcda45804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP Name:  Ammonium_PM2.5 State:  NY\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_number</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter</th>\n",
       "      <th>sample_duration_code</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>validity_indicator</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>first_max_value</th>\n",
       "      <th>first_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>site_address</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>031</td>\n",
       "      <td>0003</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>44.39308</td>\n",
       "      <td>-73.85890</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>WHITEFACE BASE</td>\n",
       "      <td>Wilmington, BASE WHITEFACE MTN, ASRC, SUNY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Essex</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>031</td>\n",
       "      <td>0003</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>44.39308</td>\n",
       "      <td>-73.85890</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-12-22</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>WHITEFACE BASE</td>\n",
       "      <td>Wilmington, BASE WHITEFACE MTN, ASRC, SUNY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Essex</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>031</td>\n",
       "      <td>0003</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>44.39308</td>\n",
       "      <td>-73.85890</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-12-16</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>WHITEFACE BASE</td>\n",
       "      <td>Wilmington, BASE WHITEFACE MTN, ASRC, SUNY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Essex</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>031</td>\n",
       "      <td>0003</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>44.39308</td>\n",
       "      <td>-73.85890</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>WHITEFACE BASE</td>\n",
       "      <td>Wilmington, BASE WHITEFACE MTN, ASRC, SUNY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Essex</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>031</td>\n",
       "      <td>0003</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>44.39308</td>\n",
       "      <td>-73.85890</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-12-04</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>WHITEFACE BASE</td>\n",
       "      <td>Wilmington, BASE WHITEFACE MTN, ASRC, SUNY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Essex</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>36</td>\n",
       "      <td>001</td>\n",
       "      <td>0005</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>42.64225</td>\n",
       "      <td>-73.75464</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>ALBANY COUNTY HEALTH DEPT</td>\n",
       "      <td>ALBANY CO. HEALTH DEPT. GREEN &amp; S FERRY STREETS</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Albany</td>\n",
       "      <td>10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>2022-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>36</td>\n",
       "      <td>001</td>\n",
       "      <td>0005</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>42.64225</td>\n",
       "      <td>-73.75464</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>ALBANY COUNTY HEALTH DEPT</td>\n",
       "      <td>ALBANY CO. HEALTH DEPT. GREEN &amp; S FERRY STREETS</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Albany</td>\n",
       "      <td>10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>2022-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>36</td>\n",
       "      <td>001</td>\n",
       "      <td>0005</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>42.64225</td>\n",
       "      <td>-73.75464</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>ALBANY COUNTY HEALTH DEPT</td>\n",
       "      <td>ALBANY CO. HEALTH DEPT. GREEN &amp; S FERRY STREETS</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Albany</td>\n",
       "      <td>10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>2022-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>36</td>\n",
       "      <td>001</td>\n",
       "      <td>0005</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>42.64225</td>\n",
       "      <td>-73.75464</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>ALBANY COUNTY HEALTH DEPT</td>\n",
       "      <td>ALBANY CO. HEALTH DEPT. GREEN &amp; S FERRY STREETS</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Albany</td>\n",
       "      <td>10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>2022-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>36</td>\n",
       "      <td>001</td>\n",
       "      <td>0005</td>\n",
       "      <td>88301</td>\n",
       "      <td>5</td>\n",
       "      <td>42.64225</td>\n",
       "      <td>-73.75464</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Ammonium Ion PM2.5 LC</td>\n",
       "      <td>7</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>No Events</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>812</td>\n",
       "      <td>Met One SASS/SuperSASS Nylon - Ion Chromatography</td>\n",
       "      <td>ALBANY COUNTY HEALTH DEPT</td>\n",
       "      <td>ALBANY CO. HEALTH DEPT. GREEN &amp; S FERRY STREETS</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Albany</td>\n",
       "      <td>10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>2022-11-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9187 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_code county_code site_number parameter_code  poc  latitude  \\\n",
       "0           36         031        0003          88301    5  44.39308   \n",
       "1           36         031        0003          88301    5  44.39308   \n",
       "2           36         031        0003          88301    5  44.39308   \n",
       "3           36         031        0003          88301    5  44.39308   \n",
       "4           36         031        0003          88301    5  44.39308   \n",
       "..         ...         ...         ...            ...  ...       ...   \n",
       "264         36         001        0005          88301    5  42.64225   \n",
       "265         36         001        0005          88301    5  42.64225   \n",
       "266         36         001        0005          88301    5  42.64225   \n",
       "267         36         001        0005          88301    5  42.64225   \n",
       "268         36         001        0005          88301    5  42.64225   \n",
       "\n",
       "     longitude  datum              parameter sample_duration_code  \\\n",
       "0    -73.85890  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "1    -73.85890  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "2    -73.85890  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "3    -73.85890  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "4    -73.85890  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "..         ...    ...                    ...                  ...   \n",
       "264  -73.75464  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "265  -73.75464  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "266  -73.75464  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "267  -73.75464  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "268  -73.75464  WGS84  Ammonium Ion PM2.5 LC                    7   \n",
       "\n",
       "    sample_duration pollutant_standard  date_local  \\\n",
       "0           24 HOUR               None  2010-12-28   \n",
       "1           24 HOUR               None  2010-12-22   \n",
       "2           24 HOUR               None  2010-12-16   \n",
       "3           24 HOUR               None  2010-12-10   \n",
       "4           24 HOUR               None  2010-12-04   \n",
       "..              ...                ...         ...   \n",
       "264         24 HOUR               None  2022-01-29   \n",
       "265         24 HOUR               None  2022-01-23   \n",
       "266         24 HOUR               None  2022-01-17   \n",
       "267         24 HOUR               None  2022-01-11   \n",
       "268         24 HOUR               None  2022-01-05   \n",
       "\n",
       "                units_of_measure event_type  observation_count  \\\n",
       "0    Micrograms/cubic meter (LC)  No Events                  1   \n",
       "1    Micrograms/cubic meter (LC)  No Events                  1   \n",
       "2    Micrograms/cubic meter (LC)  No Events                  1   \n",
       "3    Micrograms/cubic meter (LC)  No Events                  1   \n",
       "4    Micrograms/cubic meter (LC)  No Events                  1   \n",
       "..                           ...        ...                ...   \n",
       "264  Micrograms/cubic meter (LC)  No Events                  1   \n",
       "265  Micrograms/cubic meter (LC)  No Events                  1   \n",
       "266  Micrograms/cubic meter (LC)  No Events                  1   \n",
       "267  Micrograms/cubic meter (LC)  No Events                  1   \n",
       "268  Micrograms/cubic meter (LC)  No Events                  1   \n",
       "\n",
       "     observation_percent validity_indicator  arithmetic_mean  first_max_value  \\\n",
       "0                  100.0                  Y            0.107            0.107   \n",
       "1                  100.0                  Y            0.027            0.027   \n",
       "2                  100.0                  Y            0.035            0.035   \n",
       "3                  100.0                  Y            0.378            0.378   \n",
       "4                  100.0                  Y            0.082            0.082   \n",
       "..                   ...                ...              ...              ...   \n",
       "264                100.0                  Y            0.280            0.280   \n",
       "265                100.0                  Y            1.100            1.100   \n",
       "266                100.0                  Y            0.150            0.150   \n",
       "267                100.0                  Y            0.080            0.080   \n",
       "268                100.0                  Y            0.760            0.760   \n",
       "\n",
       "     first_max_hour   aqi method_code  \\\n",
       "0                 0  None         812   \n",
       "1                 0  None         812   \n",
       "2                 0  None         812   \n",
       "3                 0  None         812   \n",
       "4                 0  None         812   \n",
       "..              ...   ...         ...   \n",
       "264               0  None         812   \n",
       "265               0  None         812   \n",
       "266               0  None         812   \n",
       "267               0  None         812   \n",
       "268               0  None         812   \n",
       "\n",
       "                                                method  \\\n",
       "0    Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "1    Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "2    Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "3    Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "4    Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "..                                                 ...   \n",
       "264  Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "265  Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "266  Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "267  Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "268  Met One SASS/SuperSASS Nylon - Ion Chromatography   \n",
       "\n",
       "               local_site_name  \\\n",
       "0               WHITEFACE BASE   \n",
       "1               WHITEFACE BASE   \n",
       "2               WHITEFACE BASE   \n",
       "3               WHITEFACE BASE   \n",
       "4               WHITEFACE BASE   \n",
       "..                         ...   \n",
       "264  ALBANY COUNTY HEALTH DEPT   \n",
       "265  ALBANY COUNTY HEALTH DEPT   \n",
       "266  ALBANY COUNTY HEALTH DEPT   \n",
       "267  ALBANY COUNTY HEALTH DEPT   \n",
       "268  ALBANY COUNTY HEALTH DEPT   \n",
       "\n",
       "                                        site_address     state  county  \\\n",
       "0         Wilmington, BASE WHITEFACE MTN, ASRC, SUNY  New York   Essex   \n",
       "1         Wilmington, BASE WHITEFACE MTN, ASRC, SUNY  New York   Essex   \n",
       "2         Wilmington, BASE WHITEFACE MTN, ASRC, SUNY  New York   Essex   \n",
       "3         Wilmington, BASE WHITEFACE MTN, ASRC, SUNY  New York   Essex   \n",
       "4         Wilmington, BASE WHITEFACE MTN, ASRC, SUNY  New York   Essex   \n",
       "..                                               ...       ...     ...   \n",
       "264  ALBANY CO. HEALTH DEPT. GREEN & S FERRY STREETS  New York  Albany   \n",
       "265  ALBANY CO. HEALTH DEPT. GREEN & S FERRY STREETS  New York  Albany   \n",
       "266  ALBANY CO. HEALTH DEPT. GREEN & S FERRY STREETS  New York  Albany   \n",
       "267  ALBANY CO. HEALTH DEPT. GREEN & S FERRY STREETS  New York  Albany   \n",
       "268  ALBANY CO. HEALTH DEPT. GREEN & S FERRY STREETS  New York  Albany   \n",
       "\n",
       "              city cbsa_code                         cbsa date_of_last_change  \n",
       "0    Not in a city      None                         None          2016-03-09  \n",
       "1    Not in a city      None                         None          2016-03-09  \n",
       "2    Not in a city      None                         None          2016-03-09  \n",
       "3    Not in a city      None                         None          2016-03-09  \n",
       "4    Not in a city      None                         None          2016-03-09  \n",
       "..             ...       ...                          ...                 ...  \n",
       "264         Albany     10580  Albany-Schenectady-Troy, NY          2022-11-10  \n",
       "265         Albany     10580  Albany-Schenectady-Troy, NY          2022-11-10  \n",
       "266         Albany     10580  Albany-Schenectady-Troy, NY          2022-11-10  \n",
       "267         Albany     10580  Albany-Schenectady-Troy, NY          2022-11-10  \n",
       "268         Albany     10580  Albany-Schenectady-Troy, NY          2022-11-10  \n",
       "\n",
       "[9187 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_base= 'https://aqs.epa.gov/data/api/dailyData/byState?email=yz4343@columbia.edu&key=saffronhawk77'\n",
    "def info(param,year,state):\n",
    "    url_info = '&param='+ str(param) + '&bdate=' + str(year) +'0101&edate=' + str(year) +'1231&state=' + str(state)\n",
    "    return url_info\n",
    "Y = np.arange(2010,2023,1) # Time range\n",
    "df_ap = pd.DataFrame()\n",
    "param = 88301# param\n",
    "state = 36 #State\n",
    "if param == 42101:\n",
    "    name = 'CO'\n",
    "if param == 88301:\n",
    "    name = 'Ammonium_PM2.5'\n",
    "if param == 88403:\n",
    "    name = 'Sulfate_PM2.5'\n",
    "if param == 88306:\n",
    "    name = 'Nitrate_PM2.5'\n",
    "if param == 42603:\n",
    "    name = 'NOx'\n",
    "if param == 42602:\n",
    "    name = 'NO2'\n",
    "if param == 42401:\n",
    "    name = 'SO2'\n",
    "if state == 36:\n",
    "    s_name = 'NY'\n",
    "if state == 34:\n",
    "    s_name = 'NJ'\n",
    "print('AP Name: ', name,'State: ',s_name)\n",
    "for i in range(0,len(Y)):\n",
    "    year = Y[i]\n",
    "    url_info = info(param,year,state)\n",
    "    url_base = 'https://aqs.epa.gov/data/api/dailyData/byState?email=yz4343@columbia.edu&key=saffronhawk77'\n",
    "    url = url_base + url_info\n",
    "    response = requests.get(url).json();\n",
    "    Data = response['Data'];\n",
    "    df = pd.json_normalize(response['Data']);\n",
    "    df_ap = pd.concat([df_ap,df])\n",
    "#df_ap.to_csv(\"{}_{}.txt\".format(name,s_name))\n",
    "df_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d1dd7-dc3b-461d-a6fa-34e851f2a7cc",
   "metadata": {},
   "source": [
    "# Process each pollutant data, check their time continuity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8a4e4-be4a-42ba-82ac-f31522016d55",
   "metadata": {},
   "source": [
    "## Read in individual pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ec0cb-8aa1-4a48-a56c-69e679bdb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOx_NY = pd.read_csv('NOx_NY.txt',header = [0],parse_dates=[13]);\n",
    "NOx_NJ = pd.read_csv('NOx_NJ.txt',header = [0],parse_dates=[13]);\n",
    "NO2_NY = pd.read_csv('NO2_NY.txt',header = [0],parse_dates=[13]);\n",
    "NO2_NJ = pd.read_csv('NO2_NJ.txt',header = [0],parse_dates=[13]);\n",
    "Data_CO = pd.read_csv('CO_NY.txt',header = [0],parse_dates=[13]);\n",
    "Data_NOx = pd.read_csv('NOx_NY.txt',header = [0],parse_dates=[13]);\n",
    "Data_SO2 = pd.read_csv('SO2_NY.txt',header = [0],parse_dates=[13]);\n",
    "Data_S_PM = pd.read_csv('Sulfate_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "Data_N_PM = pd.read_csv('Nitrate_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "Data_NH_PM = pd.read_csv('Ammonium_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "Data_NO2= pd.read_csv('NO2_NY.txt',header = [0],parse_dates= [13]);\n",
    "CO_NY = pd.read_csv('CO_NY.txt',header = [0],parse_dates=[13]);\n",
    "CO_NJ = pd.read_csv('CO_NJ.txt',header = [0],parse_dates=[13]);\n",
    "SO2_NY = pd.read_csv('SO2_NY.txt',header = [0],parse_dates=[13]);\n",
    "SO2_NJ = pd.read_csv('SO2_NJ.txt',header = [0],parse_dates=[13]);\n",
    "NH4_PM_NY = pd.read_csv('Ammonium_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "NH4_PM_NJ = pd.read_csv('Ammonium_PM2.5_NJ.txt',header = [0],parse_dates=[13]);\n",
    "N_PM_NY = pd.read_csv('Nitrate_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "N_PM_NJ = pd.read_csv('Nitrate_PM2.5_NJ.txt',header = [0],parse_dates=[13]);\n",
    "S_PM_NY = pd.read_csv('Sulfate_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "S_PM_NJ = pd.read_csv('Sulfate_PM2.5_NJ.txt',header = [0],parse_dates=[13]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de08e6-48da-4f66-82fb-7b1c081edc30",
   "metadata": {},
   "source": [
    "# Get the monitor site data needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0a25f-d49f-4c7c-8172-690c5f849476",
   "metadata": {},
   "source": [
    "There are 12 air pollution monitor sites in NYC and 30 air pollution monitor sites in New Jersey, but in this project, we only need 5 in NYC and 4 in NJ. Therefore, the first step is to choose the site using the group-by in pandas. The difficulty to select the right dataset is that not all sites measure the same species, and maintenance and other operations which cause time gaps and repeated measuring during the same time are very common. The good thing is all the operations notes were recorded in datasets. In this case, it is important to plot the time continuity for each site and make sure the measurements are consistent and useful. \n",
    "<br>\n",
    "\n",
    "<br>\n",
    "I wrote functions to process each site and air pollutant individually because they can have different conditions and operations happened. \n",
    "<br>\n",
    "The time continuity plots are needed for all sites with each pollutant, here I have only shown examples that show the time continuity of NOx before and after the data process (such as taking out the repeated recording with different air pollution standards, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998bff1-d56c-4238-aabe-4ff5b4ea0b8c",
   "metadata": {},
   "source": [
    "## NOx and NO2\n",
    "### Time continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a84d03-3595-408f-aa1c-53ba1f4f4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO2 and NOX\n",
    "def process_data_no2(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == 1)];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group(\"{}\".format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "\n",
    "    \n",
    "    # Remove Event\n",
    "    Ind = np.where(df_site_name['pollutant_standard'] == 'NO2 Annual 1971')\n",
    "    df_site_name_RM = df_site_name.drop(df_site_name.index[Ind[0]])\n",
    "    \n",
    "        # Check time\n",
    "    df_site_name_Diff = df_site_name_RM['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    return df_site_name_RM, days_df_name\n",
    "def process_data_nox(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == 1)];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group(\"{}\".format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "    # Check time\n",
    "    df_site_name_Diff = df_site_name['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    \n",
    "    return df_site_name, days_df_name\n",
    "def process_data_nox_el(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == 1)];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group(\"{}\".format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "\n",
    "    \n",
    "    # Remove Event\n",
    "    Ind = np.where(df_site_name['event_type'] == 'Events Included')\n",
    "    df_site_name_RM = df_site_name.drop(df_site_name.index[Ind[0]])\n",
    "    \n",
    "        # Check time\n",
    "    df_site_name_Diff = df_site_name_RM['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    return df_site_name_RM, days_df_name\n",
    "\n",
    "NOx_site_IS52, days_NOx_IS52 = process_data_nox(NOx_NY,'IS 52')\n",
    "NOx_site_PL, days_NOx_PL = process_data_nox(NOx_NY,'PFIZER LAB SITE')\n",
    "NO2_site_IS52_ori, days_NO2_IS52_ori = process_data_nox(NO2_NY,'IS 52')\n",
    "NO2_site_PL_ori, days_NO2_PL_ori = process_data_nox(NO2_NY,'PFIZER LAB SITE')\n",
    "NO2_site_IS52, days_NO2_IS52 = process_data_no2(NO2_NY,'IS 52')\n",
    "NO2_site_PL, days_NO2_PL = process_data_no2(NO2_NY,'PFIZER LAB SITE')\n",
    "NOx_site_EL, days_NOx_EL = process_data_nox_el(NOx_NJ,'Elizabeth Lab')\n",
    "NO2_site_EL, days_NO2_EL = process_data_no2(NO2_NJ,'Elizabeth Lab')\n",
    "NO2_site_JC, days_NO2_JC = process_data_no2(NO2_NJ,'Jersey City')\n",
    "NOx_site_JC, days_NOx_JC = process_data_nox_el(NOx_NJ,'Jersey City')\n",
    "NOx_site_JC_ori, days_NOx_JC_ori = process_data_nox(NOx_NJ,'Jersey City')\n",
    "NOx_site_EL_ori, days_NOx_EL_ori = process_data_nox(NOx_NJ,'Elizabeth Lab')\n",
    "\n",
    "NOx_site_Queen, days_NOx_Queen = process_data_nox(NOx_NY,'QUEENS COLLEGE 2')\n",
    "NO2_site_Queen, days_NO2_Queen = process_data_no2(NO2_NY, 'QUEENS COLLEGE 2')\n",
    "fig1 = plt.figure(1,figsize=(16,10))\n",
    "\n",
    "ax1 = plt.subplot(2,2,1)\n",
    "plt.plot(NO2_site_IS52_ori['date_local'],days_NO2_IS52_ori)\n",
    "ax1.set_ylabel('Time Interval (Days)')\n",
    "ax1.set_ylim(0,20)\n",
    "plt.title('Time Continuity NOx IS #52')\n",
    "\n",
    "ax2 = plt.subplot(2,2,2)\n",
    "plt.plot(NO2_site_IS52['date_local'],days_NO2_IS52)\n",
    "ax2.set_ylabel('Time Interval (Days)')\n",
    "ax2.set_ylim(0,20)\n",
    "plt.title('Time Continuity NO2 IS #52')\n",
    "\n",
    "ax3 = plt.subplot(2,2,3)\n",
    "plt.plot(NOx_site_JC_ori['date_local'],days_NOx_JC_ori)\n",
    "ax3.set_ylabel('Time Interval (Days)')\n",
    "ax3.set_ylim(0,20)\n",
    "plt.title('Time Continuity NOx Jersey City')\n",
    "\n",
    "ax4 = plt.subplot(2,2,4)\n",
    "plt.plot(NOx_site_JC['date_local'],days_NOx_JC)\n",
    "ax4.set_ylabel('Time Interval (Days)')\n",
    "ax4.set_ylim(0,20)\n",
    "plt.title('Time Continuity NOx Jersey City')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77162226-c55d-47b6-b475-bc53906f3fb0",
   "metadata": {},
   "source": [
    "### Merge the Data Based on Date\n",
    "For individual pollutants, after taking out all the repeated recordings, merge (pd.concat) the same pollutant with different monitor sites together based on the same DateTime. To keep the most complete dataset, first I create a continuous time-series, and merge all the data based on the date, for the position where there are missing data (time gap), put in Nan instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9495c6e-1de3-466d-b4b5-0d62c8e5847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.date_range(start = '2010-01-01',end = '2022-12-31')\n",
    "df = pd.DataFrame(index=df_date)\n",
    "NOx_site_IS52 = NOx_site_IS52.set_index('date_local')\n",
    "NOx_site_PL = NOx_site_PL.set_index('date_local')\n",
    "NOx_site_EL = NOx_site_EL.set_index('date_local')\n",
    "NOx_site_JC = NOx_site_JC.set_index('date_local')\n",
    "\n",
    "NO2_site_IS52 = NO2_site_IS52.set_index('date_local')\n",
    "NO2_site_PL = NO2_site_PL.set_index('date_local')\n",
    "NO2_site_EL = NO2_site_EL.set_index('date_local')\n",
    "NO2_site_JC = NO2_site_JC.set_index('date_local')\n",
    "\n",
    "NOx_site_Queen = NOx_site_Queen.set_index('date_local')\n",
    "NO2_site_Queen = NO2_site_Queen.set_index('date_local')\n",
    "\n",
    "NOx_NY = pd.concat([df, NOx_site_IS52.arithmetic_mean, NOx_site_PL.arithmetic_mean,NOx_site_Queen.arithmetic_mean], axis=1)\n",
    "NOx_NJ =  pd.concat([df, NOx_site_EL.arithmetic_mean,NOx_site_JC.arithmetic_mean],axis = 1)\n",
    "NOx_NY.columns = ['NOx NY IS#52','NOx NY Pfizer','NOx Queen College 2'];\n",
    "NOx_NJ.columns = ['NOX NJ Elizabeth Lab'\n",
    "                  ,'NOx NJ Jersey City'];\n",
    "NO2_NY = pd.concat([df, NO2_site_IS52.arithmetic_mean, NO2_site_PL.arithmetic_mean,NO2_site_Queen.arithmetic_mean], axis=1)\n",
    "NO2_NJ =  pd.concat([df, NO2_site_EL.arithmetic_mean,NO2_site_JC.arithmetic_mean],axis = 1)\n",
    "NO2_NY.columns = ['NO2 NY IS#52','NO2 NY Pfizer','NO2 Queen College 2'];\n",
    "NO2_NJ.columns = ['NO2 NJ Elizabeth Lab'\n",
    "                  ,'NO2 NJ Jersey City'];\n",
    "\n",
    "NOx = pd.concat([NOx_NY, NOx_NJ], axis=1)\n",
    "NO2 = pd.concat([NO2_NY, NO2_NJ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa6755-63e8-4473-94d8-3a6fb68d954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_NY = pd.read_csv('CO_NY.txt',header = [0],parse_dates=[13]);\n",
    "CO_NJ = pd.read_csv('CO_NJ.txt',header = [0],parse_dates=[13]);\n",
    "def process_data_co2(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == \"1\")];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group(\"{}\".format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "    \n",
    "    # Check time\n",
    "    df_site_name_Diff = df_site_name['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    return df_site_name, days_df_name\n",
    "CO_NY_site_CCNY, days_CO_CCNY = process_data_co2(CO_NY,'CCNY')\n",
    "CO_NJ_site_EL, days_CO_EL = process_data_co2(CO_NJ,'Elizabeth Lab')\n",
    "CO_NJ_site_E, days_CO_E = process_data_co2(CO_NJ,'Elizabeth')\n",
    "CO_NJ_site_JC, days_CO_JC = process_data_co2(CO_NJ,'Jersey City')\n",
    "CO_NY_site_Queen, days_CO_Queen = process_data_co2(CO_NY,'QUEENS COLLEGE 2')\n",
    "df_date = pd.date_range(start = '2010-01-01',end = '2022-12-31')\n",
    "df = pd.DataFrame(index=df_date)\n",
    "CO_NY_site_CCNY = CO_NY_site_CCNY.set_index('date_local')\n",
    "CO_NJ_site_EL = CO_NJ_site_EL.set_index('date_local')\n",
    "CO_NJ_site_E = CO_NJ_site_E.set_index('date_local')\n",
    "CO_NJ_site_JC = CO_NJ_site_JC.set_index('date_local')\n",
    "CO_NY_site_Queen = CO_NY_site_Queen.set_index('date_local')\n",
    "CO_NY = pd.concat([df, CO_NY_site_CCNY.arithmetic_mean, CO_NY_site_Queen.arithmetic_mean], axis=1)\n",
    "CO_NJ =  pd.concat([df, CO_NJ_site_EL.arithmetic_mean,CO_NJ_site_E.arithmetic_mean,CO_NJ_site_JC.arithmetic_mean],axis = 1)\n",
    "CO_NY.columns = ['CO CCNY','CO Queen College 2'];\n",
    "CO_NJ.columns = ['CO NJ Elizabeth Lab','CO NJ Elizabeth','CO NJ Jersey City'];\n",
    "CO = pd.concat([CO_NY, CO_NJ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d08d45-6f79-4538-b861-9e770af07c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_NY = pd.read_csv('SO2_NY.txt',header = [0],parse_dates=[13]);\n",
    "SO2_NJ = pd.read_csv('SO2_NJ.txt',header = [0],parse_dates=[13]);\n",
    "def process_data_so2(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == \"1\")];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group('{}'.format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "    # Check time\n",
    "    df_site_name_Diff = df_site_name['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    \n",
    "    df_S2 = df_site_name.loc[df_site_name['pollutant_standard'] == \"SO2 1-hour 2010\"]\n",
    "    df_Diff_S2 = df_S2['date_local'].diff()\n",
    "    days_df_S2 = df_Diff_S2.astype('timedelta64[D]')\n",
    "    \n",
    "    return df_S2, days_df_S2\n",
    "SO2_site_IS52, days_SO2_IS52 = process_data_so2(SO2_NY,'IS 52')\n",
    "SO2_site_PL, days_SO2_PL = process_data_so2(SO2_NY,'PFIZER LAB SITE')\n",
    "SO2_site_Queen, days_SO2_Queen = process_data_so2(SO2_NY, 'QUEENS COLLEGE 2')\n",
    "SO2_site_E, days_SO2_E = process_data_so2(SO2_NJ,'Elizabeth')\n",
    "SO2_site_EL, days_SO2_EL = process_data_so2(SO2_NJ,'Elizabeth Lab')\n",
    "SO2_site_JC, days_SO2_JC = process_data_so2(SO2_NJ,'Jersey City')\n",
    "df_date = pd.date_range(start = '2010-01-01',end = '2022-12-31')\n",
    "df = pd.DataFrame(index=df_date)\n",
    "SO2_site_IS52 = SO2_site_IS52.set_index('date_local')\n",
    "SO2_site_PL = SO2_site_PL.set_index('date_local')\n",
    "SO2_site_EL = SO2_site_EL.set_index('date_local')\n",
    "SO2_site_E = SO2_site_E.set_index('date_local')\n",
    "SO2_site_JC = SO2_site_JC.set_index('date_local')\n",
    "SO2_site_Queen = SO2_site_Queen.set_index('date_local')\n",
    "SO2_NY = pd.concat([df, SO2_site_IS52.arithmetic_mean, SO2_site_PL.arithmetic_mean,SO2_site_Queen.arithmetic_mean], axis=1)\n",
    "SO2_NJ =  pd.concat([df, SO2_site_EL.arithmetic_mean,SO2_site_E.arithmetic_mean,SO2_site_JC.arithmetic_mean],axis = 1)\n",
    "SO2_NY.columns = ['SO2 NY IS#52','SO2 NY Pfizer','SO2 Queen College 2'];\n",
    "SO2_NJ.columns = ['SO2 NJ Elizabeth Lab','SO2 NJ Elizabeth','SO2 NJ Jersey City'];\n",
    "SO2 = pd.concat([SO2_NY, SO2_NJ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d47445-b4f9-47c5-9bbb-c9bad1932505",
   "metadata": {},
   "outputs": [],
   "source": [
    "NH4_PM_NY = pd.read_csv('Ammonium_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "NH4_PM_NJ = pd.read_csv('Ammonium_PM2.5_NJ.txt',header = [0],parse_dates=[13]);\n",
    "N_PM_NY = pd.read_csv('Nitrate_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "N_PM_NJ = pd.read_csv('Nitrate_PM2.5_NJ.txt',header = [0],parse_dates=[13]);\n",
    "S_PM_NY = pd.read_csv('Sulfate_PM2.5_NY.txt',header = [0],parse_dates=[13]);\n",
    "S_PM_NJ = pd.read_csv('Sulfate_PM2.5_NJ.txt',header = [0],parse_dates=[13]);\n",
    "def process_data_pm(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == 7)];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group('{}'.format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "    # Check time\n",
    "    Ind = np.where(df_site_name['event_type'] == 'Events Included')\n",
    "    df_site_name_RM = df_site_name.drop(df_site_name.index[Ind[0]])\n",
    "    df_site_name_Diff = df_site_name_RM['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    return df_site_name_RM, days_df_name\n",
    "NH4_PM_NY_IS52, days_NH4_PM_NY_IS52 = process_data_pm(NH4_PM_NY, 'IS 52')\n",
    "NH4_PM_NY_DS, days_NH4_PM_NY_DS = process_data_pm(NH4_PM_NY, 'DIVISION STREET')\n",
    "NH4_PM_NY_Queen, days_NH4_PM_NY_Queen = process_data_pm(NH4_PM_NY, 'QUEENS COLLEGE 2')\n",
    "NH4_PM_NJ_EL, days_NH4_PM_NJ_EL = process_data_pm(NH4_PM_NJ, 'Elizabeth Lab')\n",
    "NH4_PM_NJ_FH, days_NH4_PM_NJ_FH = process_data_pm(NH4_PM_NJ, 'Newark Firehouse')\n",
    "df_date = pd.date_range(start = '2010-01-01',end = '2022-12-31')\n",
    "df = pd.DataFrame(index=df_date)\n",
    "NH4_PM_NY_IS52 = NH4_PM_NY_IS52.set_index('date_local')\n",
    "NH4_PM_NY_DS = NH4_PM_NY_DS.set_index('date_local')\n",
    "NH4_PM_NJ_EL = NH4_PM_NJ_EL.set_index('date_local')\n",
    "NH4_PM_NJ_FH = NH4_PM_NJ_FH.set_index('date_local')\n",
    "NH4_PM_NY_Queen = NH4_PM_NY_Queen.set_index('date_local')\n",
    "NH4_PM_NY = pd.concat([df, NH4_PM_NY_IS52.arithmetic_mean, NH4_PM_NY_DS.arithmetic_mean, NH4_PM_NY_Queen.arithmetic_mean], axis=1)\n",
    "NH4_PM_NJ =  pd.concat([df, NH4_PM_NJ_EL.arithmetic_mean,NH4_PM_NJ_FH.arithmetic_mean],axis = 1)\n",
    "NH4_PM_NY.columns = ['Ammonium PM2.5 NY IS#52','Ammonium PM2.5 NY Division Street','Ammonium PM2.5 Queen College 2'];\n",
    "NH4_PM_NJ.columns = ['Ammonium PM2.5 NJ Elizabeth Lab','Ammonium PM2.5 NJ Newark Firehouse'];\n",
    "NH4_PM = pd.concat([NH4_PM_NY, NH4_PM_NJ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ecf48-055a-40bb-ba03-6f6e99becf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_pm_n(df,name):\n",
    "    #Select Data that have 1 Hour Sample Duration\n",
    "    df_method = df.loc[(df['sample_duration_code'] == 7)];\n",
    "\n",
    "    # Group the data based on 'local_site_name'\n",
    "    df_site = df_method.groupby('local_site_name')\n",
    "    df_site_name = df_site.get_group('{}'.format(name))\n",
    "\n",
    "    df_site_name = df_site_name.sort_values(by=\"date_local\")\n",
    "    # Check time\n",
    "    Ind = np.where(df_site_name['event_type'] == 'Events Included')\n",
    "    df_site_name_RM = df_site_name.drop(df_site_name.index[Ind[0]])\n",
    "    Ind2 = np.where(df_site_name_RM['poc'] == 1)\n",
    "    df_site_name_RM2 = df_site_name_RM.drop(df_site_name.index[Ind2[0]])\n",
    "    df_site_name_Diff = df_site_name_RM2['date_local'].diff()\n",
    "    days_df_name = df_site_name_Diff.astype('timedelta64[D]')\n",
    "    return df_site_name_RM2, days_df_name\n",
    "N_PM_NY_IS52, days_N_PM_NY_IS52 = process_data_pm_n(N_PM_NY, 'IS 52')\n",
    "N_PM_NY_DS, days_N_PM_NY_DS = process_data_pm_n(N_PM_NY, 'DIVISION STREET')\n",
    "N_PM_NY_Queen, days_N_PM_NY_Queen = process_data_pm_n(N_PM_NY, 'QUEENS COLLEGE 2')\n",
    "N_PM_NJ_EL, days_N_PM_NJ_EL = process_data_pm_n(N_PM_NJ, 'Elizabeth Lab')\n",
    "N_PM_NJ_FH, days_N_PM_NJ_FH = process_data_pm_n(N_PM_NJ, 'Newark Firehouse')\n",
    "N_PM_NY_IS52 = N_PM_NY_IS52.set_index('date_local')\n",
    "N_PM_NY_DS = N_PM_NY_DS.set_index('date_local')\n",
    "N_PM_NJ_EL = N_PM_NJ_EL.set_index('date_local')\n",
    "N_PM_NJ_FH = N_PM_NJ_FH.set_index('date_local')\n",
    "N_PM_NY_Queen = N_PM_NY_Queen.set_index('date_local')\n",
    "df_date = pd.date_range(start = '2010-01-01',end = '2022-12-31')\n",
    "df = pd.DataFrame(index=df_date)\n",
    "N_PM_NY = pd.concat([df, N_PM_NY_IS52.arithmetic_mean, N_PM_NY_DS.arithmetic_mean, N_PM_NY_Queen.arithmetic_mean], axis=1)\n",
    "N_PM_NJ =  pd.concat([df, N_PM_NJ_EL.arithmetic_mean,N_PM_NJ_FH.arithmetic_mean],axis = 1)\n",
    "N_PM_NY.columns = ['Nitrate PM2.5 NY IS#52','Nitrate PM2.5 NY Division Street','Nitrate PM2.5 Queen College 2'];\n",
    "N_PM_NJ.columns = ['Nitrate PM2.5 NJ Elizabeth Lab','Nitrate PM2.5 NJ Newark Firehouse'];\n",
    "N_PM = pd.concat([N_PM_NY, N_PM_NJ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca5bd7-1f30-44b1-9c84-36943e552eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_PM_NY_IS52, days_S_PM_NY_IS52 = process_data_pm_n(S_PM_NY, 'IS 52')\n",
    "S_PM_NY_DS, days_S_PM_NY_DS = process_data_pm_n(S_PM_NY, 'DIVISION STREET')\n",
    "S_PM_NJ_EL, days_S_PM_NJ_EL = process_data_pm_n(S_PM_NJ, 'Elizabeth Lab')\n",
    "S_PM_NJ_FH, days_S_PM_NJ_FH = process_data_pm_n(S_PM_NJ, 'Newark Firehouse')\n",
    "S_PM_NY_Queen, days_S_PM_NY_Queen = process_data_pm_n(S_PM_NY, 'QUEENS COLLEGE 2')\n",
    "S_PM_NY_IS52 = S_PM_NY_IS52.set_index('date_local')\n",
    "S_PM_NY_DS = S_PM_NY_DS.set_index('date_local')\n",
    "S_PM_NJ_EL = S_PM_NJ_EL.set_index('date_local')\n",
    "S_PM_NJ_FH = S_PM_NJ_FH.set_index('date_local')\n",
    "S_PM_NY_Queen = S_PM_NY_Queen.set_index('date_local')\n",
    "S_PM_NY = pd.concat([df, S_PM_NY_IS52.arithmetic_mean, S_PM_NY_DS.arithmetic_mean,S_PM_NY_Queen.arithmetic_mean], axis=1)\n",
    "S_PM_NJ =  pd.concat([df, S_PM_NJ_EL.arithmetic_mean,S_PM_NJ_FH.arithmetic_mean],axis = 1)\n",
    "S_PM_NY.columns = ['Sulfate PM2.5 NY IS#52','Sulfate PM2.5 NY Division Street','Sulfate PM2.5 Queen College 2'];\n",
    "S_PM_NJ.columns = ['Sulfate PM2.5 NJ Elizabeth Lab','Sulfate PM2.5 NJ Newark Firehouse'];\n",
    "S_PM = pd.concat([S_PM_NY, S_PM_NJ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb305406-985b-4e1c-9fb4-1a0142bd27a2",
   "metadata": {},
   "source": [
    "# Total Trend & Seasonal trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4d6bd-a71d-49f8-a1ed-024c7b28e340",
   "metadata": {},
   "source": [
    "After selecting the sites for different pollutants, and processing the data properly, merge the data based on the DateTime for the next step. Again, to keep the complete dataset, keep the continuous time-series, and put in Nan for miss data if there are time gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789e0f5-a3f1-440c-ae7f-fc2c0fc7bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.concat([NH4_PM,N_PM,S_PM,SO2,CO,NOx,NO2],axis = 1)\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31adc6a9-89e9-4c67-b6ab-0512d39f052c",
   "metadata": {},
   "source": [
    "# Raw Data View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbeb509-ab3e-4ea4-b319-5eee38abe16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Queen = Data.filter(regex='Queen')\n",
    "\n",
    "fig, axes = plt.subplots(figsize = (16,8),nrows = 3)\n",
    "Queen['SO2 Queen College 2'].plot(ax=axes[0])\n",
    "#Queen_pollutant['SO2 Queen College 2'].resample('3M').mean().plot(ax = axes[0],label = '3 Month Mean',color = 'k')\n",
    "Queen['NOx Queen College 2'].plot(ax=axes[2])\n",
    "#Queen_pollutant['NOx Queen College 2'].resample('3M').mean().plot(ax = axes[1],label = '3 Month Mean',color = 'k')\n",
    "Queen['CO Queen College 2'].plot(ax=axes[1])\n",
    "axes[0].set_ylabel('SO2 (ppb)',fontsize = 15)\n",
    "axes[2].set_ylabel('NOx (ppb)',fontsize = 15)\n",
    "axes[1].set_ylabel('CO (ppm)',fontsize = 15)\n",
    "#axes[3].set_ylabel('NO2 (oob)')\n",
    "axes[0].set_title('Air Pollution in New York City (Queens College Monitoring Site)')\n",
    "axes[0].legend(fontsize = 15)\n",
    "axes[2].legend(fontsize = 15)\n",
    "axes[1].legend(fontsize = 15)\n",
    "\n",
    "fig2, ax = plt.subplots(figsize = (16,12),nrows = 3)\n",
    "Queen['Ammonium PM2.5 Queen College 2'].dropna().plot(ax=ax[0])\n",
    "#Q['Ammonium PM2.5 Queen College 2'].resample('3M').mean().plot(ax = ax[0],label = '3 Month Mean',color = 'k')\n",
    "Queen['Nitrate PM2.5 Queen College 2'].dropna().plot(ax = ax[2])\n",
    "#Q['Nitrate PM2.5 Queen College 2'].resample('3M').mean().plot(ax = ax[1],label = '3 Month Mean',color = 'k')\n",
    "Queen['Sulfate PM2.5 Queen College 2'].dropna().plot(ax = ax[1])\n",
    "#Q['Sulfate PM2.5 Queen College 2'].resample('3M').mean().plot(ax = ax[2],label = '3 Month Mean',color = 'k')\n",
    "ax[0].set_ylabel('Ammonium PM2.5 (Î¼g/m3)',fontsize = 15)\n",
    "ax[2].set_ylabel('Nitrate PM2.5 (Î¼g/m3)',fontsize = 15)\n",
    "ax[1].set_ylabel('Sulfate PM2.5 (Î¼g/m3)',fontsize = 15)\n",
    "ax[0].set_title('Fine Particulate Matter in New York City (Queens College Monitoring Site)',fontsize = 15)\n",
    "ax[0].legend(fontsize = 15)\n",
    "ax[2].legend(fontsize = 15)\n",
    "ax[1].legend(fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f31c6f-9312-4eaa-a2d7-d181139e8ffb",
   "metadata": {},
   "source": [
    "## Speciated PM2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda101c-73bd-42ea-864f-2b41b5afce0b",
   "metadata": {},
   "source": [
    "For speciate PM2.5, resampled the data as seasonal (3M) and annual, then calculate the mean of each season and annual.\n",
    "<br>\n",
    "<br>\n",
    "The figure shows that all speciated PM2.5 have strong seasonal cycles. For Ammonium and Sulfate PM 2.5, there are significant decreases over 12 years, especially from 2012 to 2016, when CHP happened. After 2018, the decreasing trend slowed down and almost had a flat changing rate. \n",
    "For Nitrate PM2.5, there are seasonal cycles as well, but the decrease over the years is not very noticeable. \n",
    "<br>\n",
    "<br>\n",
    "There are no noticeable speciated PM2.5 level differences between NYC and NJ \n",
    "<br>\n",
    "<br>\n",
    "The specific number of PM2.5 changes shown above the figure: \n",
    "<br>\n",
    "Sulfate PM2.5 changed largest: more than 1 $Î¼g/m^3$\n",
    "<br>\n",
    "Ammonium PM2.5: around 0.7 $Î¼g/m^3$\n",
    "<br>\n",
    "Nitrate PM2.5: around 0.3 $Î¼g/m^3$, even saw increase for Newark Firehouse monitor site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719b935-fa69-4e43-904e-fab298ba13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16,16)\n",
    "ax1 = plt.subplot(3,2,1)\n",
    "Data['Ammonium PM2.5 NY IS#52'].dropna().resample('Y').mean().plot(ax=ax1,alpha = 0.8, color = 'deepskyblue')\n",
    "print('Ammonium PM2.5 NY IS#52 Level Diff between 2010 and 2018:',Data['Ammonium PM2.5 NY IS#52'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Ammonium PM2.5 NY Division Street'].dropna().resample('Y').mean().plot(ax=ax1, alpha = 0.8,  color = 'dodgerblue')\n",
    "print('Ammonium PM2.5 NY Division Street Level Diff between 2010 and 2018:',Data['Ammonium PM2.5 NY Division Street'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Ammonium PM2.5 Queen College 2'].dropna().resample('Y').mean().plot(ax=ax1,alpha = 0.8,color = 'blue')\n",
    "print('Ammonium PM2.5 Queen College 2 Level Diff between 2010 and 2018:',Data['Ammonium PM2.5 Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "Data['Ammonium PM2.5 NJ Elizabeth Lab'].dropna().resample('Y').mean().plot(ax=ax1,alpha = 0.8, color = 'crimson', linestyle = '--')\n",
    "print('Ammonium PM2.5 NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['Ammonium PM2.5 NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Ammonium PM2.5 NJ Newark Firehouse'].dropna().resample('Y').mean().plot(ax=ax1, alpha = 0.8 ,color = 'deeppink',linestyle = '--')\n",
    "print('Ammonium PM2.5 NJ Newark Firehouse Level Diff between 2010 and 2018:',Data['Ammonium PM2.5 NJ Newark Firehouse'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "ax1.set_title('Ammonium PM2.5 Level in NYC and NJ (Annual mean)')\n",
    "ax1.set_ylabel('Ammonium PM2.5 (Î¼g/m3)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(3,2,2)\n",
    "Data['Ammonium PM2.5 NY IS#52'].dropna().resample('3M').mean().plot(ax=ax2,alpha = 0.8, color = 'deepskyblue')\n",
    "Data['Ammonium PM2.5 NY Division Street'].dropna().resample('3M').mean().plot(ax=ax2, alpha = 0.8,  color = 'dodgerblue')\n",
    "Data['Ammonium PM2.5 Queen College 2'].dropna().resample('3M').mean().plot(ax=ax2,alpha = 0.8,color = 'blue')\n",
    "\n",
    "Data['Ammonium PM2.5 NJ Elizabeth Lab'].dropna().resample('3M').mean().plot(ax=ax2,alpha = 0.8, color = 'crimson', linestyle = '--')\n",
    "Data['Ammonium PM2.5 NJ Newark Firehouse'].dropna().resample('3M').mean().plot(ax=ax2, alpha = 0.8 ,color = 'deeppink',linestyle = '--')\n",
    "\n",
    "ax2.set_title('Ammonium PM2.5 Level in NYC and NJ (Seasonal mean)')\n",
    "ax2.set_ylabel('Ammonium PM2.5 (Î¼g/m3)')\n",
    "ax2.legend()\n",
    "\n",
    "ax3 = plt.subplot(3,2,3)\n",
    "Data['Sulfate PM2.5 NY IS#52'].dropna().resample('Y').mean().plot(ax=ax3,alpha = 0.8,color = 'deepskyblue')\n",
    "print('Sulfate PM2.5 NY IS#52 Level Diff between 2010 and 2018:',Data['Sulfate PM2.5 NY IS#52'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Sulfate PM2.5 NY Division Street'].dropna().resample('Y').mean().plot(ax=ax3, alpha = 0.8,color = 'dodgerblue')\n",
    "print('Sulfate PM2.5 NY Division Street Level Diff between 2010 and 2018:',Data['Sulfate PM2.5 NY Division Street'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Sulfate PM2.5 Queen College 2'].dropna().resample('Y').mean().plot(ax=ax3,alpha = 0.8,color = 'blue')\n",
    "print('Sulfate PM2.5 Queen College 2 Level Diff between 2010 and 2018:',Data['Sulfate PM2.5 Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "\n",
    "Data['Sulfate PM2.5 NJ Elizabeth Lab'].dropna().resample('Y').mean().plot(ax=ax3,alpha = 0.8,color = 'crimson', linestyle = '--')\n",
    "print('Sulfate PM2.5 NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['Sulfate PM2.5 NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Sulfate PM2.5 NJ Newark Firehouse'].dropna().resample('Y').mean().plot(ax=ax3, alpha = 0.8,color = 'deeppink', linestyle = '--')\n",
    "print('Sulfate PM2.5 NJ Newark Firehouse Level Diff between 2010 and 2018:',Data['Sulfate PM2.5 NJ Newark Firehouse'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "\n",
    "ax3.set_title('Sulfate PM2.5 Level in NYC and NJ (Annual mean)')\n",
    "ax3.set_ylabel('SulfatePM2.5 (Î¼g/m3)')\n",
    "ax3.legend()\n",
    "\n",
    "ax4 = plt.subplot(3,2,4)\n",
    "Data['Sulfate PM2.5 NY IS#52'].dropna().resample('3M').mean().plot(ax=ax4,alpha = 0.8,color = 'deepskyblue')\n",
    "Data['Sulfate PM2.5 NY Division Street'].dropna().resample('3M').mean().plot(ax=ax4, alpha = 0.8,color = 'dodgerblue')\n",
    "Data['Sulfate PM2.5 Queen College 2'].dropna().resample('3M').mean().plot(ax=ax4,alpha = 0.8,color = 'blue')\n",
    "\n",
    "Data['Sulfate PM2.5 NJ Elizabeth Lab'].dropna().resample('3M').mean().plot(ax=ax4,alpha = 0.8,color = 'crimson', linestyle = '--')\n",
    "Data['Sulfate PM2.5 NJ Newark Firehouse'].dropna().resample('3M').mean().plot(ax=ax4, alpha = 0.8,color = 'deeppink', linestyle = '--')\n",
    "\n",
    "ax4.set_title('Sulfate PM2.5 Level in NYC and NJ (Seasonal mean)')\n",
    "ax4.set_ylabel('SulfatePM2.5 (Î¼g/m3)')\n",
    "ax4.legend()\n",
    "\n",
    "ax6 = plt.subplot(3,2,6)\n",
    "Data['Nitrate PM2.5 NY IS#52'].dropna().resample('3M').mean().plot(ax=ax6,alpha = 0.8, color = 'deepskyblue')\n",
    "Data['Nitrate PM2.5 NY Division Street'].dropna().resample('3M').mean().plot(ax=ax6, alpha = 0.8, color = 'dodgerblue')\n",
    "Data['Nitrate PM2.5 Queen College 2'].dropna().resample('3M').mean().plot(ax=ax6,alpha = 0.8,color = 'blue')\n",
    "\n",
    "Data['Nitrate PM2.5 NJ Elizabeth Lab'].dropna().resample('3M').mean().plot(ax=ax6,alpha = 0.8,color = 'crimson', linestyle = '--' )\n",
    "Data['Nitrate PM2.5 NJ Newark Firehouse'].dropna().resample('3M').mean().plot(ax=ax6, alpha = 0.8 ,color = 'deeppink', linestyle = '--')\n",
    "\n",
    "ax6.set_title('Nitrate PM2.5 Level in NYC and NJ (Seasonal mean)')\n",
    "ax6.set_ylabel('Nitrate PM2.5 (Î¼g/m3)')\n",
    "ax6.legend()\n",
    "\n",
    "ax5 = plt.subplot(3,2,5)\n",
    "Data['Nitrate PM2.5 NY IS#52'].dropna().resample('Y').mean().plot(ax=ax5,alpha = 0.8, color = 'deepskyblue')\n",
    "print('Nitrate PM2.5 NY IS#52 Level Diff between 2010 and 2018:',Data['Nitrate PM2.5 NY IS#52'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Nitrate PM2.5 NY Division Street'].dropna().resample('Y').mean().plot(ax=ax5, alpha = 0.8, color = 'dodgerblue')\n",
    "print('Nitrate PM2.5 NY Division Street Level Diff between 2010 and 2018:',Data['Nitrate PM2.5 NY Division Street'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "Data['Nitrate PM2.5 Queen College 2'].dropna().resample('Y').mean().plot(ax=ax5,alpha = 0.8,color = 'blue')\n",
    "print('Nitrate PM2.5 Queen College 2 Level Diff between 2010 and 2018:',Data['Nitrate PM2.5 Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "\n",
    "Data['Nitrate PM2.5 NJ Elizabeth Lab'].dropna().resample('Y').mean().plot(ax=ax5,alpha = 0.8,color = 'crimson', linestyle = '--' )\n",
    "print('Nitrate PM2.5 NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['Nitrate PM2.5 NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "Data['Nitrate PM2.5 NJ Newark Firehouse'].dropna().resample('Y').mean().plot(ax=ax5, alpha = 0.8 ,color = 'deeppink', linestyle = '--')\n",
    "print('Nitrate PM2.5 NJ Newark Firehouse Level Diff between 2010 and 2018:',Data['Nitrate PM2.5 NJ Newark Firehouse'].dropna().resample('Y').mean().diff(periods = -8)[0],'Î¼g/m3')\n",
    "\n",
    "\n",
    "ax5.set_title('Nitrate PM2.5 Level in NYC and NJ (Annual mean)')\n",
    "ax5.set_ylabel('Nitrate PM2.5 (Î¼g/m3)')\n",
    "ax5.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab576b8-1328-464d-9209-a43e32a061ca",
   "metadata": {},
   "source": [
    "## Gaseous Pollutants\n",
    "For gas air pollutants, resampled the data as seasonal (3M) and annual, then calculate the mean of each season and annual.\n",
    "<br>\n",
    "<br>\n",
    "The figure shows that SO$_2$ have strong seasonal cycles. For SO$_2$, there are significant decreases over 12 years. After 2018, the decreasing trend slowed down and almost had a flat changing rate. \n",
    "For NO$_x$ and NO$2$, there are seasonal cycles as well, but the decrease over the years is very noticeable too. \n",
    "<br>\n",
    "<br>\n",
    "There are no noticeable speciated CO level over 12 years.\n",
    "<br>\n",
    "<br>\n",
    "It is interesting that NO$_x$ and NO$_2$ in NJ are all high level than NYC. We will look into this in next chapter.\n",
    "<br>\n",
    "<br>\n",
    "The specific number of gas air pollutants changes shown above the figure: \n",
    "<br>\n",
    "SO$_2$ changed largest: most sites are more than 1 ppb\n",
    "<br>\n",
    "NO$_x$ and NO$_2$: around  7 ppb\n",
    "<br>\n",
    "CO: not much changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006421d9-d550-4211-a4eb-2d4ca36e1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,20)\n",
    "ax1 = plt.subplot(4,2,1)\n",
    "Data['SO2 NY IS#52'].resample('Y').mean().plot(ax=ax1,alpha = 0.8,color = 'deepskyblue')\n",
    "print('SO2 NY IS#52 Level Diff between 2010 and 2018:',Data['SO2 NY IS#52'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['SO2 NY Pfizer'].resample('Y').mean().plot(ax=ax1, alpha = 0.8,color = 'dodgerblue')\n",
    "print('SO2 NY Pfizer Level Diff between 2010 and 2018:',Data['SO2 NY Pfizer'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['SO2 Queen College 2'].resample('Y').mean().plot(ax=ax1, alpha = 0.8,color = 'blue')\n",
    "print('SO2 Queen College 2 Level Diff between 2010 and 2018:',Data['SO2 Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "\n",
    "Data['SO2 NJ Elizabeth Lab'].resample('Y').mean().plot(ax=ax1,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "print('SO2 NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['SO2 NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['SO2 NJ Elizabeth'].resample('Y').mean().plot(ax=ax1,alpha = 0.7,color = 'deeppink',linestyle = '--')\n",
    "print('SO2 NJ Elizabeth Level Diff between 2010 and 2018:',Data['SO2 NJ Elizabeth'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['SO2 NJ Jersey City'].resample('Y').mean().plot(ax=ax1, alpha = 0.7 ,color = 'mediumvioletred',linestyle = '--')\n",
    "print('SO2 NJ Jersey City Level Diff between 2010 and 2018:',Data['SO2 NJ Jersey City'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "\n",
    "ax1.set_title('SO2 in NYC and NJ (Annual Mean)')\n",
    "ax1.set_ylabel('SO2 (ppb)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(4,2,2)\n",
    "Data['SO2 NY IS#52'].resample('3M').mean().plot(ax=ax2,alpha = 0.8,color = 'deepskyblue')\n",
    "Data['SO2 NY Pfizer'].resample('3M').mean().plot(ax=ax2, alpha = 0.8,color = 'dodgerblue')\n",
    "Data['SO2 Queen College 2'].resample('3M').mean().plot(ax=ax2, alpha = 0.8,color = 'blue')\n",
    "\n",
    "Data['SO2 NJ Elizabeth Lab'].resample('3M').mean().plot(ax=ax2,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "Data['SO2 NJ Elizabeth'].resample('3M').mean().plot(ax=ax2,alpha = 0.7,color = 'deeppink',linestyle = '--')\n",
    "Data['SO2 NJ Jersey City'].resample('3M').mean().plot(ax=ax2, alpha = 0.7 ,color = 'mediumvioletred',linestyle = '--')\n",
    "\n",
    "ax2.set_title('SO2 in NYC and NJ (Seasonal Mean)')\n",
    "ax2.set_ylabel('SO2 (ppb)')\n",
    "ax2.legend()\n",
    "\n",
    "ax3 = plt.subplot(4,2,3)\n",
    "Data['CO CCNY'].resample('Y').mean().plot(ax=ax3,alpha = 0.8,color = 'deepskyblue')\n",
    "print('CO CCNY Level Diff between 2010 and 2018:',Data['CO CCNY'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppm')\n",
    "Data['CO Queen College 2'].resample('Y').mean().plot(ax=ax3, alpha = 0.8,color = 'dodgerblue')\n",
    "print('CO Queen College 2 Level Diff between 2010 and 2018:',Data['CO Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppm')\n",
    "\n",
    "Data['CO NJ Elizabeth Lab'].resample('Y').mean().plot(ax=ax3,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "print('CO NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['CO NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppm')\n",
    "Data['CO NJ Elizabeth'].resample('Y').mean().plot(ax=ax3,alpha = 0.7,color = 'deeppink',linestyle = '--')\n",
    "print('CO NJ Elizabeth Level Diff between 2010 and 2018:',Data['CO NJ Elizabeth'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppm')\n",
    "Data['CO NJ Jersey City'].resample('Y').mean().plot(ax=ax3, alpha = 0.7 ,color = 'hotpink',linestyle = '--')\n",
    "print('CO NJ Jersey City Level Diff between 2010 and 2018:',Data['CO NJ Jersey City'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppm')\n",
    "\n",
    "ax3.set_title('CO in NYC and NJ (Annual Mean)')\n",
    "ax3.set_ylabel('CO (ppm)')\n",
    "ax3.legend()\n",
    "\n",
    "ax4 = plt.subplot(4,2,4)\n",
    "Data['CO CCNY'].resample('3M').mean().plot(ax=ax4,alpha = 0.8,color = 'deepskyblue')\n",
    "Data['CO Queen College 2'].resample('3M').mean().plot(ax=ax4, alpha = 0.8,color = 'dodgerblue')\n",
    "\n",
    "Data['CO NJ Elizabeth Lab'].resample('3M').mean().plot(ax=ax4,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "Data['CO NJ Elizabeth'].resample('3M').mean().plot(ax=ax4,alpha = 0.7,color = 'deeppink',linestyle = '--')\n",
    "Data['CO NJ Jersey City'].resample('3M').mean().plot(ax=ax4, alpha = 0.7 ,color = 'hotpink',linestyle = '--')\n",
    "\n",
    "ax4.set_title('CO in NYC and NJ (Seasonal Mean)')\n",
    "ax4.set_ylabel('CO (ppm)')\n",
    "ax4.legend()\n",
    "\n",
    "ax5 = plt.subplot(4,2,5)\n",
    "Data['NOx NY IS#52'].resample('Y').mean().plot(ax=ax5,alpha = 0.8,color = 'deepskyblue')\n",
    "print('NOx NY IS#52 Level Diff between 2010 and 2018:',Data['NOx NY IS#52'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['NOx NY Pfizer'].resample('Y').mean().plot(ax=ax5, alpha = 0.8,color = 'dodgerblue')\n",
    "print('NOx NY Pfizer Level Diff between 2010 and 2018:',Data['NOx NY Pfizer'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['NOx Queen College 2'].resample('Y').mean().plot(ax=ax5, alpha = 0.8,color = 'blue')\n",
    "print('NOx Queen College 2 Level Diff between 2010 and 2018:',Data['NOx Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "\n",
    "\n",
    "Data['NOX NJ Elizabeth Lab'].resample('Y').mean().plot(ax=ax5,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "print('NOX NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['NOX NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['NOx NJ Jersey City'].resample('Y').mean().plot(ax=ax5, alpha = 0.7 ,color = 'hotpink',linestyle = '--')\n",
    "print('NOx NJ Jersey City Level Diff between 2010 and 2018:',Data['NOx NJ Jersey City'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "\n",
    "ax5.set_title('NOx in NYC and NJ (Annual Mean)')\n",
    "ax5.set_ylabel('NOx (ppb)')\n",
    "ax5.legend()\n",
    "\n",
    "ax6 = plt.subplot(4,2,6)\n",
    "Data['NOx NY IS#52'].resample('3M').mean().plot(ax=ax6,alpha = 0.8,color = 'deepskyblue')\n",
    "Data['NOx NY Pfizer'].resample('3M').mean().plot(ax=ax6, alpha = 0.8,color = 'dodgerblue')\n",
    "Data['NOx Queen College 2'].resample('3M').mean().plot(ax=ax6, alpha = 0.8,color = 'blue')\n",
    "\n",
    "Data['NOX NJ Elizabeth Lab'].resample('3M').mean().plot(ax=ax6,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "Data['NOx NJ Jersey City'].resample('3M').mean().plot(ax=ax6, alpha = 0.7 ,color = 'hotpink',linestyle = '--')\n",
    "\n",
    "ax6.set_title('NOx in NYC and NJ (Seasonal Mean)')\n",
    "ax6.set_ylabel('NOx (ppb)')\n",
    "ax6.legend()\n",
    "\n",
    "ax7 = plt.subplot(4,2,7)\n",
    "Data['NO2 NY IS#52'].resample('Y').mean().plot(ax=ax7,alpha = 0.8,color = 'deepskyblue')\n",
    "print('NO2 NY IS#52 Level Diff between 2010 and 2018:',Data['NO2 NY IS#52'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['NO2 NY Pfizer'].resample('Y').mean().plot(ax=ax7, alpha = 0.8,color = 'dodgerblue')\n",
    "print('NO2 NY Pfizer Level Diff between 2010 and 2018:',Data['NO2 NY Pfizer'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['NO2 Queen College 2'].resample('Y').mean().plot(ax=ax7, alpha = 0.8,color = 'blue')\n",
    "print('NO2 Queen College 2 Level Diff between 2010 and 2018:',Data['NO2 Queen College 2'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "\n",
    "Data['NO2 NJ Elizabeth Lab'].resample('Y').mean().plot(ax=ax7,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "print('NO2 NJ Elizabeth Lab Level Diff between 2010 and 2018:',Data['NO2 NJ Elizabeth Lab'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "Data['NO2 NJ Jersey City'].resample('Y').mean().plot(ax=ax7, alpha = 0.7 ,color = 'hotpink',linestyle = '--')\n",
    "print('NO2 NJ Jersey City Level Diff between 2010 and 2018:',Data['NO2 NJ Jersey City'].dropna().resample('Y').mean().diff(periods = -8)[0],'ppb')\n",
    "\n",
    "ax7.set_title('NO2 in NYC and NJ (Annual Mean)')\n",
    "ax7.set_ylabel('NO2 (ppb)')\n",
    "ax7.legend()\n",
    "\n",
    "ax8 = plt.subplot(4,2,8)\n",
    "Data['NO2 NY IS#52'].resample('3M').mean().plot(ax=ax8,alpha = 0.8,color = 'deepskyblue')\n",
    "Data['NO2 NY Pfizer'].resample('3M').mean().plot(ax=ax8, alpha = 0.8,color = 'dodgerblue')\n",
    "Data['NO2 Queen College 2'].resample('3M').mean().plot(ax=ax8, alpha = 0.8,color = 'blue')\n",
    "\n",
    "Data['NO2 NJ Elizabeth Lab'].resample('3M').mean().plot(ax=ax8,alpha = 0.7,color = 'crimson',linestyle = '--')\n",
    "Data['NO2 NJ Jersey City'].resample('3M').mean().plot(ax=ax8, alpha = 0.7 ,color = 'hotpink',linestyle = '--')\n",
    "\n",
    "ax8.set_title('NO2 in NYC and NJ (Seasonal Mean)')\n",
    "ax8.set_ylabel('NO2 (ppb)')\n",
    "ax8.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0573a-037e-4797-a866-7033532603f2",
   "metadata": {},
   "source": [
    "# NO/NO2 Ratio to Check Why NJ has higher NOx and NO2 than NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017628d-fc89-40c4-89e1-3467916e09f9",
   "metadata": {},
   "source": [
    "The NO/NO2 ratio can be used to determine whether the pollution plume is fresh. \n",
    "During combustion, N$_2$ is oxidized to NO, and in the atmosphere, very important reaction oxides NO to NO$_2$:\n",
    "<br>\n",
    "NO + O3 â†’ NO2 + O2 + hÎ½\n",
    "<br>\n",
    "This reaction can happen in a few minutes. Therefore, when the monitor site is close to the pollutant source, the NO/NO2 tends to be large, and vice versa. \n",
    "<br>\n",
    "<br>\n",
    "Here, I compared the NO/NO$_2$ ratio of NYC and NJ by applying the scatter plot of NO and NO2 and using linear regression to find the ratio.\n",
    "Interestingly, all sites in NJ have NO.NO2 ratios are larger than 1 (around 1.5), and in NYC, the NO/NO2 ratios are all around 0.9. This means monitor sites in NJ are closer to the pollutant source than those monitor sites in NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcec11e-5c07-4a73-a48e-c675accda585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a empty NO dataset \n",
    "# Calculate NO using NOX - NO2\n",
    "NO = NO2 * 0\n",
    "NO.columns = ['NO NY IS#52','NO NY Pfizer','NO Queen College 2','NO NJ Elizabeth Lab','NO NJ Jersey City'];\n",
    "NO['NO NY IS#52'] = NOx['NOx NY IS#52'] - NO2['NO2 NY IS#52']\n",
    "NO['NO NY Pfizer'] = NOx['NOx NY Pfizer'] - NO2['NO2 NY Pfizer']\n",
    "NO['NO NJ Elizabeth Lab'] = NOx['NOX NJ Elizabeth Lab'] - NO2['NO2 NJ Elizabeth Lab']\n",
    "NO['NO NJ Jersey City'] = NOx['NOx NJ Jersey City'] - NO2['NO2 NJ Jersey City']\n",
    "NO['NO Queen College 2'] = NOx['NOx Queen College 2']- NO2['NO2 Queen College 2']\n",
    "NO2_NO = pd.concat([NO,NO2],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72171d-a052-4de8-b3c6-7b6b92800e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 15)\n",
    "ax1 = plt.subplot(3,2,1)\n",
    "Pfizer = pd.concat([NO2_NO['NO2 NY Pfizer'],NO2_NO['NO NY Pfizer']],axis = 1)\n",
    "Pfizer = Pfizer.dropna()\n",
    "plt.scatter(x = Pfizer['NO2 NY Pfizer'], y= Pfizer['NO NY Pfizer'],color = 'dodgerblue')\n",
    "plt.xlabel('NO2 (ppb)')\n",
    "plt.ylabel('NO (ppb)')\n",
    "plt.title('NY Pfizer')\n",
    "X = Pfizer.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "Y = Pfizer.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "linear_regressor = LinearRegression()  # create object for the class\n",
    "linear_regressor.fit(X, Y)  # perform linear regression\n",
    "Y_pred = linear_regressor.predict(X)  # make predictions\n",
    "a = linear_regressor.coef_[0][0]\n",
    "b = linear_regressor.intercept_[0]\n",
    "plt.plot(X, Y_pred, color='red', label = '{}x{}'.format(np.round(a,2),np.round(b,2)))\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(3,2,2)\n",
    "plt.scatter(NO2_NO['NO2 NY IS#52'],NO2_NO['NO NY IS#52'])\n",
    "IS52 = pd.concat([NO2_NO['NO2 NY IS#52'],NO2_NO['NO NY IS#52']],axis = 1)\n",
    "IS52 = IS52.dropna()\n",
    "plt.scatter(x = IS52['NO2 NY IS#52'], y= IS52['NO NY IS#52'],color = 'deepskyblue')\n",
    "plt.xlabel('NO2 (ppb)')\n",
    "plt.ylabel('NO (ppb)')\n",
    "plt.title('NY IS 52')\n",
    "X = IS52.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "Y = IS52.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "linear_regressor = LinearRegression()  # create object for the class\n",
    "linear_regressor.fit(X, Y)  # perform linear regression\n",
    "Y_pred = linear_regressor.predict(X)  # make predictions\n",
    "a = linear_regressor.coef_[0][0]\n",
    "b = linear_regressor.intercept_[0]\n",
    "plt.plot(X, Y_pred, color='red',label = '{}x{}'.format(np.round(a,2),np.round(b,2)))\n",
    "ax2.legend()\n",
    "\n",
    "ax3 = plt.subplot(3,2,3)\n",
    "Queen_R = pd.concat([NO2_NO['NO2 Queen College 2'],NO2_NO['NO Queen College 2']],axis = 1)\n",
    "Queen_R  = Queen_R.dropna()\n",
    "plt.scatter(x = Queen_R['NO2 Queen College 2'], y= Queen_R['NO Queen College 2'],color = 'blue')\n",
    "X = Queen_R .iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "Y = Queen_R .iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "linear_regressor = LinearRegression()  # create object for the class\n",
    "linear_regressor.fit(X, Y)  # perform linear regression\n",
    "a = linear_regressor.coef_[0][0]\n",
    "b = linear_regressor.intercept_[0]\n",
    "Y_pred = linear_regressor.predict(X)\n",
    "plt.plot(X, Y_pred, color='red',label = '{}x{}'.format(np.round(a,2),np.round(b,2)))\n",
    "plt.title('Queen College 2')\n",
    "plt.xlabel('NO2 (ppb)')\n",
    "plt.ylabel('NO (ppb)')\n",
    "ax3.legend()\n",
    "\n",
    "\n",
    "ax4 = plt.subplot(3,2,4)\n",
    "plt.scatter(NO2_NO['NO2 NJ Elizabeth Lab'],NO2_NO['NO NJ Elizabeth Lab'])\n",
    "EL = pd.concat([NO2_NO['NO2 NJ Elizabeth Lab'],NO2_NO['NO NJ Elizabeth Lab']],axis = 1)\n",
    "EL = EL.dropna()\n",
    "plt.scatter(x = EL['NO2 NJ Elizabeth Lab'], y= EL['NO NJ Elizabeth Lab'],color = 'crimson')\n",
    "plt.xlabel('NO2 (ppb)')\n",
    "plt.ylabel('NO (ppb)')\n",
    "plt.title('NJ Elizabeth Lab')\n",
    "X = EL.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "Y = EL.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "linear_regressor = LinearRegression()  # create object for the class\n",
    "linear_regressor.fit(X, Y)  # perform linear regression\n",
    "Y_pred = linear_regressor.predict(X)  # make predictions\n",
    "#plt.scatter(X, Y)\n",
    "a = linear_regressor.coef_[0][0]\n",
    "b = linear_regressor.intercept_[0]\n",
    "plt.plot(X, Y_pred, color='crimson',label = '{}x{}'.format(np.round(a,2),np.round(b,2)))\n",
    "ax4.legend()\n",
    "\n",
    "ax5 = plt.subplot(3,2,5)\n",
    "JC = pd.concat([NO2_NO['NO2 NJ Jersey City'],NO2_NO['NO NJ Jersey City']],axis = 1)\n",
    "JC = JC.dropna()\n",
    "plt.scatter(x = JC['NO2 NJ Jersey City'], y= JC['NO NJ Jersey City'],color = 'hotpink')\n",
    "plt.xlabel('NO2 (ppb)')\n",
    "plt.ylabel('NO (ppb)')\n",
    "plt.title('NJ Jersey City')\n",
    "X = JC.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "Y = JC.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "linear_regressor = LinearRegression()  # create object for the class\n",
    "linear_regressor.fit(X, Y)  # perform linear regression\n",
    "Y_pred = linear_regressor.predict(X)  # make predictions\n",
    "#plt.scatter(X, Y)\n",
    "a = linear_regressor.coef_[0][0]\n",
    "b = linear_regressor.intercept_[0]\n",
    "plt.plot(X, Y_pred, color='red',label = '{}x{}'.format(np.round(a,2),np.round(b,2)))\n",
    "\n",
    "plt.title('Jersey City')\n",
    "plt.xlabel('NO2 (ppb)')\n",
    "plt.ylabel('NO (ppb)')\n",
    "ax5.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab83fe-6a43-47c6-ac6e-0069aee5e232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
